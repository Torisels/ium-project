{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# potrzebne importy\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wczytanie danych\n",
    "users_df = pd.read_json(\"../data/users.jsonl\", lines=True)\n",
    "sessions_df = pd.read_json(\"../data/sessions.jsonl\", lines=True)\n",
    "products_df = pd.read_json(\"../data/products.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funkcje pomocnicze do przetwarzania danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_color(products_df):\n",
    "    for index, row in products_df.iterrows():\n",
    "        color = re.search(\"'color': '\\w+'\", str(row[\"optional_attributes\"]))\n",
    "        if color != None:\n",
    "            products_df.loc[index, \"color\"] = color.group(0)[10:-1]\n",
    "        else:\n",
    "            products_df.loc[index, \"color\"] = None\n",
    "    return products_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_and_bind(original_dataframe, feature_to_encode):\n",
    "    dummies = pd.get_dummies(original_dataframe[[feature_to_encode]], prefix=\"\", prefix_sep=\"\")\n",
    "    res = pd.concat([original_dataframe, dummies], axis=1)\n",
    "    res = res.drop([feature_to_encode], axis=1)\n",
    "    return(res) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df, columns_to_norm):\n",
    "    for feature_name in df.columns:\n",
    "        if feature_name in columns_to_norm:\n",
    "            max_value = df[feature_name].max()\n",
    "            min_value = df[feature_name].min()\n",
    "            df[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_users_views(sessions):\n",
    "    sess = sessions.copy()\n",
    "    sess['view'] = sess['event_type'].map(lambda x: 1 if x == \"VIEW_PRODUCT\" or x == \"BUY_PRODUCT\" else 0)\n",
    "    users_views = sess.groupby(['user_id', 'product_id'], as_index=False)['view'].sum()\n",
    "    \n",
    "    users_views = pd.pivot_table(users_views, values='view', index='user_id', columns='product_id')\n",
    "    users_views = users_views.fillna(0)\n",
    "    users_views = users_views.stack().reset_index()\n",
    "    users_views = users_views.rename(columns={0:'view'})\n",
    "    return users_views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_params(product_id, products):\n",
    "    ret_product = products.loc[products[\"product_id\"] == product_id]\n",
    "    ret_product = ret_product.drop(columns=\"product_id\")\n",
    "    return ret_product\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model naiwny\n",
    "\n",
    "Model naiwny korzysta z algorytmu K najbliższych sąsiadów. Na podstawie bazy wszystkich produktów obliczane są dystanse podobieństwa pomiędzy produktami na podstawie metryki cosinusowej. Wybrane atrybuty do obliczania metryk to: cena, ścieżka kategorii, ocena użytkownika. Następnie budowana jest tablica krotek: (użytkownik, produkt, liczba wyświetleń produktu) - tablica popularności danego produktu względem użytkownika. Taka tablica jest zbiorem trenującym, dla każdego użytkownika następuje sortowanie produktów malejąco według liczby wyświetleń, następnie dla najpopularniejszego produktu dla każdego użytkownika jest uruchamiany algorytm KNN znajdujący produkty najbardziej podobne do tego najchętniej oglądanego. Gdyby polecane produkty znalazły się już w tych wyświetlonych przez użytkownika to algorytm będzie szukał produktów podobnych dla mniej popularnych pozycji po to, aby użytkownik miał w polecanych produktach tylko te, których sam jeszcze nie widział. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_products_set_basic(products_df):\n",
    "    products_set = products_df.copy()\n",
    "    products_set = extract_color(products_set)\n",
    "    products_set = encode_and_bind(products_set, 'category_path')\n",
    "    products_set = products_set.drop(columns=[\"product_name\", \"brand\", \"optional_attributes\",\"weight_kg\",\"color\", \"user_rating_count\"])\n",
    "    products_set = normalize(products_set, ['price', 'user_rating'])\n",
    "    return products_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_set = prepare_products_set_basic(products_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_basic_model(train_set, k=5, algo=\"brute\", metric=\"cosine\"):\n",
    "    X = products_model_A.drop(columns=[\"product_id\"])\n",
    "    return NearestNeighbors(n_neighbors=k, algorithm=algo, metric=metric).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrs = train_basic_model(products_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zapis zserializowanego modelu oraz przetworzonych danych do pliku\n",
    "products_model_A.to_pickle(\"basic/products.pickle\")\n",
    "\n",
    "with open(\"basic/model.pickle\", \"wb\") as f:\n",
    "    pickle.dump(nbrs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendations_basic(user_id, model, users_views, products, k):\n",
    "    most_viewed = users_views.loc[users_views[\"user_id\"] == user_id].sort_values(by=[\"view\"], ascending=False)\n",
    "    most_viewed_products = list(most_viewed[\"product_id\"])\n",
    "    viewed_products = set(most_viewed[most_viewed[\"view\"] > 0.0][\"product_id\"])\n",
    "    \n",
    "    final_reccomendation = []\n",
    "    for product in most_viewed_products:\n",
    "        recommended = model.kneighbors(get_product_params(product, products), return_distance=False)\n",
    "       \n",
    "        for recommended_product in recommended[0]:\n",
    "            recommended_product_id = products.iloc[[recommended_product]]['product_id']\n",
    "            \n",
    "            pid = int(recommended_product_id)\n",
    "            if pid not in viewed_products and pid not in final_reccomendation:\n",
    "                final_reccomendation.append(int(recommended_product_id))\n",
    "            if len(final_reccomendation) == k:\n",
    "                return final_reccomendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_views_data = get_users_views(sessions_df).reset_index()\n",
    "train_m = np.random.rand(len(user_views_data)) < 0.8\n",
    "train_data = user_views_data[train_m]\n",
    "test_data = user_views_data[~train_m]\n",
    "test_users = users_df.sample(frac = 0.1)[\"user_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1600\n"
     ]
    }
   ],
   "source": [
    "user_views_data = get_users_views(sessions_df).reset_index()\n",
    "train_m = np.random.rand(len(user_views_data)) < 0.8\n",
    "train_data = user_views_data[train_m]\n",
    "test_data = user_views_data[~train_m]\n",
    "test_users = users_df.sample(frac = 0.1)[\"user_id\"]\n",
    "# ocena poprawności modelu naiwnego\n",
    "train_data_basic = train_data.copy()\n",
    "test_data_basic = test_data.copy()\n",
    "k = 5\n",
    "correct = 0\n",
    "for user in test_users:\n",
    "    recommendations = recommendations_basic(user, nbrs, train_data_basic, products_model_A, k)\n",
    "    for recommendation in recommendations:\n",
    "        view = test_data_basic.loc[(test_data_basic['product_id'] == recommendation) & (test_data_basic['user_id'] == user)]['view']\n",
    "        if view is not None and view.any():\n",
    "            correct += 1\n",
    "            \n",
    "result = correct / (k*len(test_users))\n",
    "\n",
    "print(\"{:.4f}\".format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_basic.to_pickle(\"basic/train_data.pickle\")\n",
    "test_data_basic.to_pickle(\"basic/test_data.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model zaawansowany\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, euclidean_distances, cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_sessions = sessions_df.copy()\n",
    "local_sessions['action_points'] = local_sessions['event_type'].map(lambda x: 2 if x == \"VIEW_PRODUCT\" else 5)\n",
    "actions_sums = model_B_sessions.groupby(['user_id', 'product_id'], as_index=False)['action_points'].sum()\n",
    "actions_sums = pd.pivot_table(actions_sums, values='action_points', index='user_id', columns='product_id')\n",
    "actions_sums = actions_sums.fillna(0)\n",
    "actions_users = actions_sums.copy()\n",
    "actions_sums = actions_sums.stack().reset_index().rename(columns={0:\"action_points\"})\n",
    "actions_sums[\"view_ocurred\"] = actions_sums['action_points'].apply(lambda x: True if x > 0 else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podział na zbiory testowy i trenujący\n",
    "train_data = actions_sums[train_m]\n",
    "test_data = actions_sums[~train_m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_and_product = pd.merge(train_data, products_df, on=\"product_id\", how=\"left\")\n",
    "user_and_product = user_and_product[['user_id', 'product_id', 'product_name', 'price', 'user_rating', 'user_rating_count']]\n",
    "user_and_product = normalize(user_and_product, [\"price\",'user_rating_count','user_rating'])\n",
    "product_cat = user_and_product[['product_id', 'product_name', 'price', 'user_rating', 'user_rating_count']].drop_duplicates('product_id')\n",
    "\n",
    "tfidf_name = TfidfVectorizer()\n",
    "products_content_name = tfidf_name.fit_transform(product_cat['product_name'].unique())\n",
    "cosine_sim_name = linear_kernel(products_content_name, products_content_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_matrix = np.reciprocal(euclidean_distances(np.array(product_cat['price']).reshape(-1,1))+1)\n",
    "framed_price_matrix = pd.DataFrame(price_matrix,columns=product_cat['product_id'],index=product_cat['product_id'])\n",
    "\n",
    "rating_mtrx = np.reciprocal(euclidean_distances(np.array(product_cat['user_rating']).reshape(-1, 1)) +1)\n",
    "framed_rating_matrix = pd.DataFrame(rating_matrix,columns=product_cat['product_id'],index=product_cat['product_id'])\n",
    "\n",
    "rating_count_mtrx = np.reciprocal(euclidean_distances(np.array(product_cat['user_rating_count']).reshape(-1,1))+1)\n",
    "framed_rating_count_matrix = pd.DataFrame(rating_matrix,columns=product_cat['product_id'],index=product_cat['product_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = framed_price_matrix.multiply(framed_rating_matrix).multiply(framed_rating_count_matrix).multiply(cosine_sim_name)\n",
    "content_matrix = actions_users.dot(similarity_matrix)\n",
    "content_df = content_matrix.stack().reset_index()\n",
    "content_df = content_df.rename(columns={'level_0':'user_id','level_1':'product_id', 0:'score'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_pickle(\"train_data_advanced.pickle\")\n",
    "test_data.to_pickle(\"test_data_advanced.pickle\")\n",
    "actions_sums.to_pickle(\"user_actions_advanced.pickle\")\n",
    "content_df.to_pickle(\"content_df_advanced.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendation_advanced(user_id, content_matrix, train_set, K):\n",
    "    content_df = content_matrix.loc[content_matrix['user_id'] == user_id]\n",
    "    content_df = content_df.set_index(\"product_id\")\n",
    "    user_content_df = content_df.sort_values(by=\"score\", ascending=False)\n",
    "    indices_to_drop = list(train_set[(train_set[\"view_ocurred\"]==True) & (train_set[\"user_id\"]==user_id)][\"product_id\"])\n",
    "    user_content_df = user_content_df.drop(indices_to_drop)\n",
    "    return list(user_content_df.head(K).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2900\n"
     ]
    }
   ],
   "source": [
    "K = 5\n",
    "correct = 0\n",
    "for user in test_users:\n",
    "    recommendations = get_recommendation_advanced(user, content_df, train_data, K)\n",
    "    for recommendation in recommendations:\n",
    "        view = test_data[(test_data['product_id'] == recommendation) & (test_data['user_id'] == user)]['view_ocurred']\n",
    "        if view.any() and view.item() == True:\n",
    "            correct = correct + 1\n",
    "result = correct / (K * len(test_users))\n",
    "\n",
    "print(\"{:.4f}\".format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[193, 299, 205, 226, 292, 204, 148, 208, 178, 284, 222, 242, 235, 108, 267, 135, 139, 287, 259, 227, 176, 149, 201, 233, 250, 217, 116, 200, 237, 128, 155, 277, 232, 293, 288, 202, 198, 195, 118, 240, 191, 175, 146, 115, 167, 152, 184, 169, 239, 159, 256, 218, 192, 290, 271, 105, 289, 216, 206, 120, 166, 170, 140, 179, 223, 134, 173, 281, 194, 294, 276, 263, 123, 151, 114, 301, 172, 214, 279, 268, 125, 157, 187, 154, 163, 264, 231, 207, 106, 225, 181, 112, 147, 270, 103, 158, 295, 261, 162, 199]\n",
      "[102, 104, 107, 109, 110, 111, 113, 117, 119, 121, 122, 124, 126, 127, 129, 130, 131, 132, 133, 136, 137, 138, 141, 142, 143, 144, 145, 150, 153, 156, 160, 161, 164, 165, 168, 171, 174, 177, 180, 182, 183, 185, 186, 188, 189, 190, 196, 197, 203, 209, 210, 211, 212, 213, 215, 219, 220, 221, 224, 228, 229, 230, 234, 236, 238, 241, 243, 244, 245, 246, 247, 248, 249, 251, 252, 253, 254, 255, 257, 258, 260, 262, 265, 266, 269, 272, 273, 274, 275, 278, 280, 282, 283, 285, 286, 291, 296, 297, 298, 300]\n"
     ]
    }
   ],
   "source": [
    "# losowy wybor uzytkownikow do eksperymentu A/B online\n",
    "\n",
    "basic_model_users_ab = users_df.sample(frac=0.5)\n",
    "advanced_model_users_ab = users_df.drop(basic_model_users_ab.index)\n",
    "basic_model_users_ab = list(basic_model_users_ab[\"user_id\"])\n",
    "advanced_model_users_ab = list(advanced_model_users_ab[\"user_id\"])\n",
    "print(list(basic_model_users_ab))\n",
    "print(list(advanced_model_users_ab))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
